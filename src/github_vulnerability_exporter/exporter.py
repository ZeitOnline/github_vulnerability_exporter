from datetime import datetime
import argparse
import collections
import logging
import os
import prometheus_client
import prometheus_client.core
import prometheus_client.exposition
import requests
import sys
import time


log = logging.getLogger(__name__)
LOG_FORMAT = '%(asctime)s %(levelname)-5.5s %(message)s'


class Gauge(prometheus_client.core.GaugeMetricFamily):

    def clone(self):
        return type(self)(
            self.name, self.documentation, labels=self._labelnames)


class VulnerabilityCollector:

    _cache_value = None
    _cache_updated_at = 0

    def configure(self, owner, authtoken, include_forked, cache_ttl):
        self.owner = owner
        self.authtoken = authtoken
        self.include_forked = include_forked
        self.cache_ttl = cache_ttl

    METRICS = {
        'vulnerabilities': Gauge(
            'github_vulnerability_alerts',
            'Security vulnerabilities reported by GitHub, by repository',
            labels=['repository', 'status']),
        'scrape_duration': Gauge(
            'ghvuln_scrape_duration_seconds',
            'Duration of GitHub API scrape'),
    }

    def describe(self):
        return self.METRICS.values()

    def collect(self):
        start = time.time()

        if start - self._cache_updated_at <= self.cache_ttl:
            log.info('Returning cached result from %s',
                     datetime.fromtimestamp(self._cache_updated_at))
            return self._cache_value

        # Use a separate instance for each scrape request, to prevent
        # race conditions with simultaneous scrapes.
        metrics = {
            key: value.clone() for key, value in self.METRICS.items()}

        log.info('Retrieving data from GitHub API')
        has_next = True
        cursor = ''
        while has_next:
            r = self.graphql(self.QUERY % {
                'owner': self.owner,
                'forked': str(self.include_forked).lower(),
                'cursor': ', after:"%s"' % cursor if cursor else '',
                'repo_batch_size': self.REPO_BATCH_SIZE,
                'vuln_batch_size': self.VULN_BATCH_SIZE,
            })
            data = r['data']['repositoryOwner']['repositories']
            page = data['pageInfo']
            has_next = page['hasNextPage']
            cursor = page['endCursor']

            for repo in data['nodes']:
                status = collections.Counter()
                for alert in repo['vulnerabilityAlerts']['nodes']:
                    status[bool(alert.get('dismissedAt'))] += 1
                reponame = '%s/%s' % (self.owner, repo['name'])
                metrics['vulnerabilities'].add_metric(
                    (reponame, 'active'), status[False])
                metrics['vulnerabilities'].add_metric(
                    (reponame, 'dismissed'), status[True])
                # Does not fit the prometheus data model:
                #   securityVulnerability {
                #     package {
                #       name
                #    }
                #  }
                # packages = [
                #     x['securityVulnerability']['package']['name']
                #     for x in alerts]
        stop = time.time()
        metrics['scrape_duration'].add_metric((), stop - start)
        self._cache_value = metrics.values()
        self._cache_updated_at = stop
        return self._cache_value

    REPO_BATCH_SIZE = 50
    VULN_BATCH_SIZE = 10
    QUERY = """query {
    repositoryOwner(login:"%(owner)s") {
      repositories(isFork:%(forked)s, first:%(repo_batch_size)s%(cursor)s) {
        nodes {
          name vulnerabilityAlerts(first:%(vuln_batch_size)s) {
            nodes {
              dismissedAt
            }
          }
        }

        pageInfo {
          hasNextPage
          endCursor
        }
      }
    }}
    """

    def graphql(self, query):
        r = requests.post(
            'https://api.github.com/graphql', json={'query': query},
            headers={
                'Authorization': 'Bearer %s' % self.authtoken,
                # vulnerabilities are currently in beta, see
                # <https://developer.github.com/v4/previews/>
                'Accept': 'application/vnd.github.vixen-preview+json',
            })
        r.raise_for_status()
        return r.json()


COLLECTOR = VulnerabilityCollector()
# We don't want the `process_` and `python_` metrics, we're a collector,
# not an exporter.
REGISTRY = prometheus_client.core.CollectorRegistry()
REGISTRY.register(COLLECTOR)
APP = prometheus_client.make_wsgi_app(REGISTRY)


def main():
    parser = argparse.ArgumentParser(
        description='Export GitHub vulnerability alerts as prometheus metrics')
    parser.add_argument('--owner', help='GitHub owner name')
    parser.add_argument('--authtoken', help='GitHub API token')
    parser.add_argument('--forked', action='store_true',
                        help='Include forked repositories')
    parser.add_argument('--host', default='', help='Listen host')
    parser.add_argument('--port', default=9597, type=int, help='Listen port')
    parser.add_argument('--ttl', default=600, type=int, help='Cache TTL')
    options = parser.parse_args()
    if not options.owner:
        options.owner = os.environ.get('GITHUB_OWNER')
    if not options.authtoken:
        options.authtoken = os.environ.get('GITHUB_AUTHTOKEN')

    if not all([options.owner, options.authtoken]):
        parser.print_help()
        raise SystemExit(1)
    logging.basicConfig(
        stream=sys.stdout, level=logging.INFO, format=LOG_FORMAT)

    COLLECTOR.configure(options.owner, options.authtoken, options.forked,
                        options.ttl)

    log.info('Listening on 0.0.0.0:%s', options.port)
    httpd = prometheus_client.exposition.make_server(
        options.host, options.port, APP,
        handler_class=prometheus_client.exposition._SilentHandler)
    httpd.serve_forever()
